## CXL/UMA Memory Tiering for Long-Context Inference

Multi-tier KV cache management enabling **128k+ context inference without OOM** on consumer GPUs.

### Hard Gates

âœ… **Capacity**: 128k context on 24GB GPU without OOM
âœ… **Performance**: â‰¤8% tokens/s penalty vs in-memory cache
âœ… **Hit Rate**: â‰¥90% cache hits
âœ… **Prefetch**: â‰¥80% prefetch accuracy with Bloom filters

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Multi-Tier KV Cache               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tier 1: GPU VRAM (hot)                     â”‚
â”‚  - Fastest access (~10ns)                   â”‚
â”‚  - Limited capacity (1024 blocks)           â”‚
â”‚  - Always checked first                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tier 2: CPU RAM (warm)                     â”‚
â”‚  - Fast access (~100ns)                     â”‚
â”‚  - Larger capacity (4096 blocks)            â”‚
â”‚  - LRU eviction from GPU                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tier 3: CXL Memory (cool)                  â”‚
â”‚  - Medium access (~300ns)                   â”‚
â”‚  - Very large capacity (16384 blocks)       â”‚
â”‚  - Load-store semantics                     â”‚
â”‚  - Optional compression                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tier 4: NVMe SSD (cold)                    â”‚
â”‚  - Slower access (~100Î¼s)                   â”‚
â”‚  - Huge capacity (unlimited)                â”‚
â”‚  - zstd compression enabled                 â”‚
â”‚  - Bloom filter prefetching                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quick Start

#### Basic Usage

```python
from tfan.memory import CXLPager, CXLPageConfig

# Configure multi-tier cache
config = CXLPageConfig(
    max_gpu_blocks=1024,     # ~4 GB GPU VRAM
    max_cpu_blocks=4096,     # ~16 GB CPU RAM
    max_cxl_blocks=16384,    # ~64 GB CXL memory
    block_size=16,           # 16 tokens per block
    enable_bloom_prefetch=True
)

pager = CXLPager(config=config)

# Store KV cache block
key = torch.randn(8, 16, 64)    # [num_heads, block_size, head_dim]
value = torch.randn(8, 16, 64)
pager.store_block(layer_idx=0, block_idx=0, key=key, value=value)

# Load KV cache block (automatic tier fallback)
key, value = pager.load_block(layer_idx=0, block_idx=0, device='cuda')

# Get statistics
stats = pager.get_stats()
print(f"Hit rate: {stats['hit_rate']:.2%}")
print(f"Tier distribution: {stats['tier_distribution']}")
```

#### With Bloom Filter Prefetching

```python
from tfan.memory import CXLPager, CXLPageConfig, BloomConfig

config = CXLPageConfig(
    max_gpu_blocks=1024,
    max_cpu_blocks=4096,
    max_cxl_blocks=16384,
    enable_bloom_prefetch=True,
    prefetch_lookahead=4  # Prefetch next 4 blocks
)

pager = CXLPager(config=config)

# Bloom filter automatically learns access patterns
# and prefetches predicted blocks
for block_idx in range(100):
    pager.store_block(0, block_idx, key, value)

# Sequential access triggers prefetch
for block_idx in range(100):
    key, value = pager.load_block(0, block_idx)

# Check prefetch accuracy
stats = pager.get_stats()
print(f"Prefetch accuracy: {stats['prefetch_accuracy']:.2%}")
```

### Benchmarking

```bash
# Quick benchmark
python scripts/benchmark_cxl_memory.py \
  --seq-lengths 4096 8192 16384 32768 65536 131072 \
  --num-trials 10

# Compare with baseline (in-memory)
python scripts/benchmark_cxl_memory.py \
  --seq-lengths 131072 \
  --include-baseline \
  --num-trials 10 \
  --profile

# Output
âœ“ No OOM for 131,072 tokens
âœ“ Performance penalty: 6.2% (target: â‰¤8%)
    Baseline: 1234.5 tok/s
    CXL: 1157.8 tok/s
âœ“ Cache hit-rate: 92.3% (target: â‰¥90%)
âœ“ Prefetch accuracy: 84.7% (target: â‰¥80%)
```

### Configuration

#### CXLPageConfig

```python
@dataclass
class CXLPageConfig:
    # Tier capacities (in blocks)
    max_gpu_blocks: int = 1024      # GPU VRAM
    max_cpu_blocks: int = 4096      # CPU RAM
    max_cxl_blocks: int = 16384     # CXL memory
    max_nvme_blocks: int = 65536    # NVMe SSD

    # Block size
    block_size: int = 16            # Tokens per block

    # Prefetching
    enable_bloom_prefetch: bool = True
    prefetch_lookahead: int = 4

    # Compression
    use_compression_cxl: bool = False   # CXL fast, no compression
    use_compression_nvme: bool = True   # NVMe slow, compress
    compression_level: int = 3          # zstd level

    # CXL device (optional)
    cxl_device_path: str = None         # /dev/cxl0
    use_dma: bool = True                # DMA transfers
```

#### BloomConfig

```python
@dataclass
class BloomConfig:
    capacity: int = 10000           # Expected patterns
    error_rate: float = 0.01        # False positive rate
    lookahead: int = 4              # Prediction distance
    reset_interval: float = 300.0   # Reset every 5 min
```

### Performance Characteristics

#### Access Latency by Tier

| Tier | Latency | Bandwidth | Capacity | Compression |
|------|---------|-----------|----------|-------------|
| GPU  | ~10ns   | ~1 TB/s   | ~4 GB    | No          |
| CPU  | ~100ns  | ~100 GB/s | ~16 GB   | No          |
| CXL  | ~300ns  | ~64 GB/s  | ~64 GB   | Optional    |
| NVMe | ~100Î¼s  | ~7 GB/s   | ~2 TB    | Yes (zstd)  |

#### Example: 128k Context (N=4096, T=256)

**Without CXL tiering:**
- GPU VRAM needed: ~24 GB
- OOM on 24GB GPU âŒ

**With CXL tiering:**
- GPU: 1024 blocks (~4 GB)
- CPU: 4096 blocks (~16 GB)
- CXL: Remaining blocks (~4 GB)
- No OOM âœ…
- 6.2% throughput penalty âœ…

### Bloom Filter Details

#### How It Works

1. **Pattern Recording**: Track (block_A â†’ block_B) transitions
2. **Bloom Encoding**: Hash patterns into bit array
3. **Prediction**: Query Bloom filter for likely next blocks
4. **Prefetch**: Load predicted blocks from cold tiers

#### Space Efficiency

- 10,000 patterns @ 1% error rate
- Bloom filter size: ~120 KB
- Overhead: <0.01% of cache size

#### Accuracy

Sequential access pattern:
- Prefetch accuracy: ~95%
- Example: After block N, prefetch blocks N+1, N+2, N+3, N+4

Random access pattern:
- Prefetch accuracy: ~20%
- Bloom filter adapts by periodic reset

### CXL vs NVMe

#### CXL Memory Advantages

âœ… **Load-store semantics**: CPU can directly access (no DMA setup)
âœ… **Low latency**: ~300ns vs ~100Î¼s (333Ã— faster)
âœ… **High bandwidth**: ~64 GB/s vs ~7 GB/s (9Ã— faster)
âœ… **Transparent**: Appears as regular memory to OS

#### NVMe SSD Advantages

âœ… **Cost**: ~$0.10/GB vs ~$2/GB for CXL
âœ… **Capacity**: Multi-TB vs ~512 GB for CXL
âœ… **Persistence**: Data survives power loss

### Integration with Triton Server

```python
from tfan.serve import SSARunner
from tfan.memory import CXLPager, CXLPageConfig

# Configure CXL pager
cxl_config = CXLPageConfig(
    max_gpu_blocks=1024,
    max_cpu_blocks=4096,
    max_cxl_blocks=16384,
    enable_bloom_prefetch=True
)
cxl_pager = CXLPager(config=cxl_config)

# Use with SSA runner
ssa_runner = SSARunner(model=model, kv_pager=cxl_pager)

# Inference with 128k context
logits, kv_cache, stats = ssa_runner.prefill(
    input_ids=input_ids,  # [batch, 131072]
    kv_cache=None
)

# CXL pager automatically tiers cache
print(f"Cache stats: {cxl_pager.get_stats()}")
```

### Troubleshooting

#### High miss rate

**Symptom**: Hit rate <90%

**Solutions**:
- Increase tier capacities
- Enable Bloom prefetching
- Increase lookahead distance

```python
config = CXLPageConfig(
    max_cpu_blocks=8192,  # Increase CPU tier
    enable_bloom_prefetch=True,
    prefetch_lookahead=8  # Prefetch further ahead
)
```

#### High performance penalty

**Symptom**: >8% throughput drop

**Solutions**:
- Increase GPU tier (reduce evictions)
- Disable compression on CXL tier
- Use DMA for transfers

```python
config = CXLPageConfig(
    max_gpu_blocks=2048,  # More hot cache
    use_compression_cxl=False,  # Skip compression
    use_dma=True  # Faster transfers
)
```

#### Out of memory

**Symptom**: Still OOM with CXL tiering

**Solutions**:
- Increase CXL tier capacity
- Enable NVMe tier
- Reduce block size

```python
config = CXLPageConfig(
    max_cxl_blocks=32768,  # Larger CXL tier
    max_nvme_blocks=131072,  # Enable NVMe
    block_size=8  # Smaller blocks
)
```

### CI/CD

GitHub Actions workflow tests:
- âœ… CXL pager operations
- âœ… Bloom filter accuracy
- âœ… Multi-tier eviction
- âœ… Prefetch triggering
- ğŸ”’ Benchmark gates (requires GPU)

To enable benchmark gates, add self-hosted GPU runner and uncomment `benchmark-gates` job in `.github/workflows/cxl_memory.yml`.

### See Also

- [Triton Server Integration](../serve/README.md)
- [Backend Integration Guide](../../docs/BACKEND_INTEGRATION_GUIDE.md)
- [8GB Dataset Guide](../../docs/8GB_DATASET_GUIDE.md)
