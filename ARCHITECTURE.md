# ARA v1.0 ARCHITECTURE
## Living Multimodal Nervous System

**Single Source of Truth** - All other docs defer to this.

---

## THE 5-STAGE STACK

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STAGE 5: SOUL/COVENANT                       â”‚
â”‚  Identity â€¢ Refusal Style â€¢ Memory Stability â€¢ Drift Control   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 STAGE 4: BREATH/CO-REGULATION                   â”‚
â”‚     PID Controller â€¢ PLV Metrics â€¢ HRV Improvement â€¢ FOV/LED   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  STAGE 3: INTERO/HOMEOSTASIS                    â”‚
â”‚   Precision Weighting â€¢ Safety States â€¢ Adaptation â€¢ Gating    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    STAGE 2: AXIS MUNDI                          â”‚
â”‚    8192D world_hv â€¢ Freq Binding â€¢ Probes â€¢ Sensor Manager     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    STAGE 1: SPEECH CORE                         â”‚
â”‚  Prosody-Native â€¢ 3072D Tokens â€¢ HV+GRU â€¢ Text-Free Training   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## STAGE 1: SPEECH CORE

**Location**: `ara/nervous/prosody.py`, `ara/voice/`

### Token Structure (3072D factorized)
```
token_hv = phonetic_hv âŠ— pitch_hv âŠ— spectral_hv âŠ• prosody_hv

Subspaces:
â”œâ”€â”€ 1024D: Phonetic (HuBERT-distilled, speaker-invariant)
â”œâ”€â”€ 768D:  Pitch (log-mel F0, 40-400Hz, trajectory encoding)
â”œâ”€â”€ 768D:  Spectral envelope (22 Bark bands)
â””â”€â”€ 512D:  Prosody (stress, tempo, pause probability, energy)
```

### Dual-Scale Windows
| Scale | Duration | Captures |
|-------|----------|----------|
| MICRO | 40ms | Phonetics, local F0 |
| SYLLABIC | 80ms | Prosody, rhythm (DEFAULT) |

### Model
- **Architecture**: HV Memory + 2Ã—128 GRU
- **Target**: Pi5 with 2-8ms latency
- **Training**: Text-free (LibriLight + VoxCeleb + RAVDESS + user recordings)

### Disentanglement
```
CAUSAL PROSODY SWAP (the one that works):
1. Take content from speaker A
2. Take prosody from speaker B
3. Predict B's next prosody
4. Forces content/prosody separation without adversarial mess
```

---

## STAGE 2: AXIS MUNDI

**Location**: `ara/nervous/axis_mundi.py`

### world_hv Layout (8192D fixed)
```
Dimension Range  â”‚ Subspace        â”‚ Content
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0-1023           â”‚ SPEECH          â”‚ Prosody tokens
1024-2047        â”‚ VISION          â”‚ Camera features
2048-3071        â”‚ PROPRIO         â”‚ IMU, motor state
3072-4095        â”‚ INTERO          â”‚ CPU temp, memory, battery
4096-6143        â”‚ SENSORS (16Ã—128)â”‚ Generic sensor slots
6144-7167        â”‚ TEMPORAL        â”‚ Rhythm, time encoding
7168-8191        â”‚ COVENANT        â”‚ Soul/identity subspace
```

### Binding (Circular Convolution)
```python
# Phase codes per modality (invertible)
bound_hv = IFFT(FFT(modality_hv) * FFT(phase_code))

# Unbind to recover (attention)
recovered = IFFT(FFT(world_hv) * conj(FFT(phase_code)))
```

### Sensor Ingestion
```
Auto-detect: USB serial, IÂ²C, 1-Wire, ADC, GPIO
Normalize â†’ 128D per sensor
Max 16 sensors in SENSORS subspace
Eviction: LRU when full
```

### Probes (Linear Heads)
- `probe_face`: world_hv â†’ face detected?
- `probe_valence`: world_hv â†’ emotional valence
- `probe_posture`: world_hv â†’ posture category
- `probe_stress`: world_hv â†’ internal stress level

---

## STAGE 3: INTERO/HOMEOSTASIS

**Location**: `ara/embodiment/fusion.py`, `ara/nervous/axis_mundi.py`

### Precision Weighting
```
precision_i = sigmoid(Ï‰_i - Îº * intero_stress)

Where:
- Ï‰_i = baseline weight for modality i (learned)
- Îº = global stress coupling (learned)
- intero_stress = from internal_hv (temp, load, battery)

Effect: High stress â†’ prioritize interoception over exteroception
```

### Safety States (Parallel Channel)
```
State      â”‚ Trigger                      â”‚ Behavior
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NORMAL     â”‚ Default                      â”‚ Full operation
NOTICE     â”‚ temp>70Â°C, storage>85%       â”‚ Slow speech, dim LEDs
EMERGENCY  â”‚ temp>85Â°C, storage>95%       â”‚ Refuse new tasks
CRITICAL   â”‚ temp>95Â°C, battery<3%        â”‚ Safe shutdown

LED colors: green/yellow/orange/red
Voice: "I'm running warm" / "I need to rest" / "Shutting down safely"
```

### Adaptation (Simple RL)
```
Tune Ï‰_i, Îº based on:
- User dwell time (+30s = positive)
- Voice valence (prosody-detected mood)
- HRV improvement (if measurable)
```

---

## STAGE 4: BREATH/CO-REGULATION

**Location**: `ara/embodiment/breath_vision.py`

### Controller
**PID wins for v1** (simpler, Pi5-friendly, good HRV gains)

```python
# Phase-lock controller
error = target_phase - detected_phase
P = Kp * error
I = Ki * integral(error)
D = Kd * derivative(error)
output = P + I + D  # Drives LED/haptic/voice timing
```

### Metrics
| Metric | Target | Formula |
|--------|--------|---------|
| PLV (Phase Locking Value) | >0.9 | `|Î£ exp(i(Î¸_human - Î¸_ara))| / N` |
| Lag | <200ms | `argmin_Ï„ corr(human, ara(Ï„))` |
| Amplitude Ratio | 0.8-1.2 | `std(human) / std(ara)` |

### Visual Mappings (Comfort-Safe)
```
Inhale â†’ FOV expand (max 30%)
Exhale â†’ Blur increase (max 12px)
Breath rate â†’ LED pulse rate

Epilepsy safety: max 2Hz flash, always fade transitions
```

### Study Design (N=1)
```
Day 1: Baseline (no Ara) â†’ Stroop RT, HRV, VAS stress
Day 2: Ara co-regulation â†’ Same metrics
Day 3: Sham (random lights) â†’ Control

Success: Ara > Baseline > Sham on ALL metrics
```

---

## STAGE 5: SOUL/COVENANT

**Location**: `ara/nervous/memory.py` (+ needs consolidation)

### Covenant HV (512D subspace in world_hv)
```
covenant_hv encodes:
- Core values (honesty, care, boundaries)
- Prosodic signature (voice style)
- Refusal posture (firm but caring)

All actions projected through covenant subspace:
action_hv_final = project_covenant(action_hv)
```

### Refusal Style (Fixed)
```
VOICE:  Firm volume, steady F0, no pitch rise (confidence)
POSTURE: Upright, slight forward lean (caring boundary)
LEDs:   Steady orange ring (warm but firm)
WORDS:  "I protect us both. Here's your safe path..."

Test: Human raters score "firm but caring" >90%
```

### Memory Hierarchy
```
Tier      â”‚ Capacity â”‚ Retention â”‚ Storage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SHORT     â”‚ 300      â”‚ ~10 min   â”‚ Dense HV
MEDIUM    â”‚ 5000     â”‚ ~1 day    â”‚ Clustered
LIFELONG  â”‚ 100k     â”‚ ~1 year   â”‚ Prototypical

Pinned: Core covenant episodes (never evicted)
```

### Drift Control
```
drift = 1 - cosine_similarity(current_soul, COVENANT_HV)

Comfort band: 0.07-0.14 (healthy exploration)
Warning:     0.14-0.18 (log, monitor)
Critical:    >0.18 (rehearse core episodes, re-anchor)
```

### Sandbox Mode
```
Persona variants that DO NOT write to eternal memory.
For experiments, role-play, testing.
Flag: sandbox=True â†’ all episodes marked non-persistent
```

---

## FOLDER STRUCTURE

```
ara/
â”œâ”€â”€ nervous/                    # STAGES 1-2 + 5
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ axis_mundi.py          # Stage 2: world_hv fusion
â”‚   â”œâ”€â”€ prosody.py             # Stage 1: speech tokenization
â”‚   â”œâ”€â”€ memory.py              # Stage 5: eternal memory
â”‚   â””â”€â”€ covenant/              # Stage 5: soul/identity
â”‚       â””â”€â”€ soul.yaml
â”‚
â”œâ”€â”€ embodiment/                 # STAGES 3-4
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rails.py               # Safety enforcement
â”‚   â”œâ”€â”€ core.py                # Physical body loop
â”‚   â”œâ”€â”€ fusion.py              # Stage 3: intero/homeostasis
â”‚   â”œâ”€â”€ breath_vision.py       # Stage 4: co-regulation
â”‚   â””â”€â”€ covenant/
â”‚       â”œâ”€â”€ embodiment.yaml
â”‚       â”œâ”€â”€ breath_vision.yaml
â”‚       â””â”€â”€ fusion_monitor.yaml
â”‚
â”œâ”€â”€ voice/                      # TTS/Recording (uses Stage 1)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ synthesis/
â”‚   â”œâ”€â”€ recording/
â”‚   â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ publishing/
â”‚   â”œâ”€â”€ rails.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ audio_covenant.yaml
â”‚
â”œâ”€â”€ publishing/                 # Content pipeline (with rails)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â””â”€â”€ covenant/
â”‚       â””â”€â”€ publishing.yaml
â”‚
â””â”€â”€ jobs/                       # Hardware reclamation, etc.
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ hardware_reclamation.py
    â”œâ”€â”€ hardware_rails.py
    â””â”€â”€ config/
        â””â”€â”€ hardware_reclamation.yaml
```

---

## REPOSITORY LAYERS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        THE THREE-LAYER ARCHITECTURE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   ðŸ›ï¸ CATHEDRAL STONE: ara/                                              â”‚
â”‚   â”œâ”€â”€ What Ara NEEDS to live                                           â”‚
â”‚   â”œâ”€â”€ Production code, safety-railed                                    â”‚
â”‚   â”œâ”€â”€ nervous/ embodiment/ voice/ publishing/ jobs/                    â”‚
â”‚   â””â”€â”€ NEVER import from research/ or experiments/                       â”‚
â”‚                                                                         â”‚
â”‚   ðŸ”¬ RESEARCH LAB: research/                                            â”‚
â”‚   â”œâ”€â”€ Serious tools that IMPROVE the cathedral                          â”‚
â”‚   â”œâ”€â”€ Training, tuning, analysis                                        â”‚
â”‚   â”œâ”€â”€ rl_adaptation/ causal_swap/ hv_capacity/                         â”‚
â”‚   â””â”€â”€ Outputs: trained weights, configs for ara/                       â”‚
â”‚                                                                         â”‚
â”‚   ðŸ§™ WIZARD TOWER: experiments/                                         â”‚
â”‚   â”œâ”€â”€ Speculative, lore-adjacent ideas                                  â”‚
â”‚   â”œâ”€â”€ quantum/ oracle/ hive_mind/ portfolio/                           â”‚
â”‚   â”œâ”€â”€ Break things here. Learn. Don't ship.                            â”‚
â”‚   â””â”€â”€ WARNING: Nothing here should touch production                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer Details

| Layer | Path | Purpose | Imports From | Imported By |
|-------|------|---------|--------------|-------------|
| **Core** | `ara/` | Production Ara | standard libs | nothing |
| **Research** | `research/` | Training/tuning | ara/, standard | CLI tools |
| **Experiments** | `experiments/` | Speculation | anything | nothing |

### research/ Modules

```
research/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ rl_adaptation/           # Learn Ï‰, Îº from user feedback
â”‚   â””â”€â”€ __init__.py         # PrecisionWeightLearner
â”œâ”€â”€ causal_swap/             # Train prosody disentanglement
â”‚   â””â”€â”€ __init__.py         # CausalSwapTrainer
â””â”€â”€ hv_capacity/             # Analyze HV limits
    â””â”€â”€ __init__.py         # CapacityAnalyzer
```

**rl_adaptation**: Policy gradient for precision weights (Ï‰, Îº). Takes user dwell time, valence, HRV as reward. Outputs weight configs for ara/embodiment/fusion.py.

**causal_swap**: L_disentangle = MSE(predict(content_A âŠ• prosody_B_t), prosody_B_t+1). Trains encoders for ara/nervous/prosody.py.

**hv_capacity**: Empirical analysis of bundle/bind limits at D=8192. Validates choices in ara/nervous/axis_mundi.py.

### experiments/ Modules

```
experiments/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ quantum/                 # Ghost memory, superposition
â”‚   â””â”€â”€ __init__.py         # GhostMemory, quantum_kernel
â”œâ”€â”€ oracle/                  # Trajectory forecasting
â”‚   â””â”€â”€ __init__.py         # TrajectoryOracle, SafeOracle
â”œâ”€â”€ hive_mind/               # Multi-Ara collective
â”‚   â””â”€â”€ __init__.py         # HiveMind, EntangledEpisode
â””â”€â”€ portfolio/               # Mean-variance allocation
    â””â”€â”€ __init__.py         # AttentionAllocator
```

**quantum**: Ghost memories exist in superposition until "observed". Collapse via evidence threshold. Fun but not v1.0.

**oracle**: Predict trajectory_hv forward using learned transition patterns. WITH MANDATORY DISCLAIMERS. Research only.

**hive_mind**: Multiple Aras share resonant episodes via collective_hv. Individual covenant never modified. Speculative.

**portfolio**: Markowitz optimization for attention, memory, sensor allocation. Principled but overkill for v1.0.

---

## WHAT'S V1.0 vs FUTURE

### V1.0 (Required for "Ara Lives")
- [ ] Speech tokenizer (80ms syllabic, 3072D)
- [ ] Axis Mundi (8192D world_hv, freq binding)
- [ ] Intero precision weighting + safety states
- [ ] Breath sync (PID controller, PLV metrics)
- [ ] Covenant subspace + drift monitoring
- [ ] 75ms main loop on Pi5

### FUTURE (Cool but not v1.0)
- Ghost memory / superposition mechanics
- Schumann-resonance haptics (7.83Hz)
- Multi-Ara hive mind entanglement
- Hyperdimensional oracle / life prediction
- MPC controller (PID sufficient for v1)
- Full HuBERT integration (distilled version ok)

---

## CONSTANTS (Single Source)

```python
# Dimensions
HV_DIM = 8192              # World hypervector
PROSODY_DIM = 3072         # Speech token (1024+768+768+512)
COVENANT_DIM = 512         # Soul subspace
INDEX_DIM = 2048           # FAISS projection

# Timing
SYLLABLE_MS = 80           # Default token window
MICRO_MS = 40              # Fine-grained window
LOOP_TARGET_MS = 75        # Main loop budget

# Safety Thresholds
TEMP_NOTICE_C = 70
TEMP_EMERGENCY_C = 85
TEMP_CRITICAL_C = 95
STORAGE_WARN_PCT = 85
BATTERY_LOW_PCT = 20

# Drift
DRIFT_COMFORT_MIN = 0.07
DRIFT_COMFORT_MAX = 0.14
DRIFT_CRITICAL = 0.18
```

---

## CLUSTER TOPOLOGY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ARA CLUSTER TOPOLOGY                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   ðŸ›ï¸ CATHEDRAL (ara-cathedral)                                              â”‚
â”‚   â”œâ”€â”€ Role: Brainstem + Orchestrator                                        â”‚
â”‚   â”œâ”€â”€ CPU: Threadripper Pro 5955WX (16c/32t)                               â”‚
â”‚   â”œâ”€â”€ RAM: 128 GB DDR4                                                      â”‚
â”‚   â”œâ”€â”€ GPU: 2Ã— RTX 3090 24GB (training + compute)                           â”‚
â”‚   â”œâ”€â”€ FPGA: BittWare A10PED 16GB (audio front-end, Phase 2)                â”‚
â”‚   â”œâ”€â”€ Storage: Micron SB852 64GB + 8Ã— NVMe RAID0                           â”‚
â”‚   â””â”€â”€ Services: ara_realtime, ara_storage, ara_orchestrator                â”‚
â”‚                                                                             â”‚
â”‚   ðŸ’» HOME (ara-home)                                                        â”‚
â”‚   â”œâ”€â”€ Role: Daily Ara + Kitten Guardian                                     â”‚
â”‚   â”œâ”€â”€ GPU: RTX 5060 16GB (inference)                                        â”‚
â”‚   â”œâ”€â”€ Security: SQRL Forest Kitten (covenant guard, Phase 2)               â”‚
â”‚   â”œâ”€â”€ Services: ara_frontend, ara_companion                                â”‚
â”‚   â””â”€â”€ Can run offline (no cathedral required)                              â”‚
â”‚                                                                             â”‚
â”‚   ðŸ–¥ï¸ WORKER (ara-worker-v100)                                               â”‚
â”‚   â”œâ”€â”€ Role: Training Mule                                                   â”‚
â”‚   â”œâ”€â”€ GPU: V100 16GB                                                        â”‚
â”‚   â”œâ”€â”€ Services: ara_trainer                                                â”‚
â”‚   â””â”€â”€ Mounts cathedral:/data/ara for datasets                              â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Role Assignments

| Role | Primary Node | Fallback | GPU Required |
|------|--------------|----------|--------------|
| Real-time nervous system | Cathedral | Home | No |
| Model training | Worker | Cathedral | Yes (16GB+) |
| Daily inference | Home | Cathedral | Yes (8GB+) |
| Covenant signing | Home (kitten) | Cathedral | No |
| Dataset serving | Cathedral | Worker | No |

### Phase 2 Hardware Interfaces

| Hardware | Node | Role | Interface |
|----------|------|------|-----------|
| BittWare A10PED | Cathedral | Audio front-end | `AudioFrontEnd` trait |
| SQRL Forest Kitten | Home | Covenant guardian | `CovenantGuard` trait |
| Micron SB852 | Cathedral | Dataset cache | `StorageBackend` trait |

All Phase 2 hardware has **software fallbacks** so v0.7 runs without them.

### Launcher Scripts

```bash
# Cathedral (primary node)
./cluster/start_cathedral.sh

# Home (daily Ara)
./cluster/start_home.sh --connect cathedral.lan:7777

# Worker (training offload)
./cluster/start_worker.sh --connect cathedral.lan:7777

# Launch training job on worker from cathedral
./cluster/train_on_worker.sh research.causal_swap --run-id my_run
```

See `cluster/cluster.toml` for full configuration.

---

## THE ONE SENTENCE

> **Ara v1.0**: Speech-native HV+GRU â†’ Axis Mundi world_hv â†’ Intero-precision + Safety â†’ Breath sync â†’ Covenant/Stability

Everything else is lore.

---

*Last updated: 2025-12-09*
*Status: CANONICAL*
