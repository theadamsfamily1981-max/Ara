\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{tcolorbox}

% Custom colors
\definecolor{aracolor}{HTML}{00FFAA}
\definecolor{notecolor}{HTML}{2A2A3A}

% Custom boxes
\newtcolorbox{notebox}{
    colback=notecolor,
    colframe=aracolor,
    boxrule=1pt,
    arc=3pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt
}

% Title
\title{%
    \textbf{Hierarchical Gaussian Filter for Computational Psychiatry}\\[0.5em]
    \large Methods and Theoretical Foundation for Ara/NeuroBalance
}
\author{Ara Project Documentation}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This document provides the theoretical foundation for the Hierarchical Gaussian Filter (HGF) implementation used in the Ara cognitive architecture and NeuroBalance neurofeedback platform. We establish the connection between classical Kalman filtering and hierarchical Bayesian inference, derive the key HGF update equations, and map computational parameters to psychiatric phenotypes. The goal is to provide a rigorous but accessible reference for researchers and developers working with these systems.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Background: Bayesian Filtering for Learning Under Uncertainty}
%==============================================================================

\subsection{The Filtering Problem}

Consider an agent observing a sequence of outcomes $u_1, u_2, \ldots, u_t$ generated by some hidden process. The agent's task is to infer the current state of the hidden process and predict future observations. This is the \emph{filtering problem}.

Formally, we seek the posterior distribution:
\begin{equation}
    p(x_t \mid u_{1:t}) \propto p(u_t \mid x_t) \, p(x_t \mid u_{1:t-1})
\end{equation}
where $x_t$ is the hidden state and $u_{1:t}$ denotes all observations up to time $t$.

\subsection{The Kalman Filter}

For linear Gaussian systems, the optimal solution is the \textbf{Kalman filter}. Consider the state-space model:
\begin{align}
    x_t &= A x_{t-1} + w_t, \quad w_t \sim \mathcal{N}(0, Q) \label{eq:kf_state}\\
    u_t &= C x_t + v_t, \quad v_t \sim \mathcal{N}(0, R) \label{eq:kf_obs}
\end{align}
where $Q$ is the process noise covariance and $R$ is the observation noise covariance.

The Kalman filter maintains Gaussian beliefs $\mathcal{N}(\mu_t, \Sigma_t)$ and updates them via:

\paragraph{Prediction Step:}
\begin{align}
    \hat{\mu}_t &= A \mu_{t-1} \\
    \hat{\Sigma}_t &= A \Sigma_{t-1} A^\top + Q
\end{align}

\paragraph{Update Step:}
\begin{align}
    K_t &= \hat{\Sigma}_t C^\top (C \hat{\Sigma}_t C^\top + R)^{-1} \label{eq:kalman_gain}\\
    \mu_t &= \hat{\mu}_t + K_t (u_t - C \hat{\mu}_t) \label{eq:kalman_update}\\
    \Sigma_t &= (I - K_t C) \hat{\Sigma}_t
\end{align}

The \textbf{Kalman gain} $K_t$ in Equation~\eqref{eq:kalman_gain} is the precision-weighted balance between prior and sensory information. Rewriting in terms of precisions ($\pi = \Sigma^{-1}$):
\begin{equation}
    K_t = \frac{\pi_{\text{prior}}}{\pi_{\text{prior}} + \pi_{\text{sensory}}}
\end{equation}

This is the key insight: \emph{belief updates are precision-weighted prediction errors}.

\subsection{Limitations of the Kalman Filter}

The standard Kalman filter assumes:
\begin{enumerate}
    \item \textbf{Linear dynamics}: $A$ and $C$ are constant matrices.
    \item \textbf{Known, fixed noise}: $Q$ and $R$ are constant.
    \item \textbf{Gaussian distributions}: All densities remain Gaussian.
\end{enumerate}

In real-world learning, these assumptions often fail:
\begin{itemize}
    \item Observations may be binary (e.g., reward/no reward).
    \item Environmental volatility may change over time.
    \item The agent may need to \emph{learn} the noise statistics.
\end{itemize}

The Hierarchical Gaussian Filter addresses these limitations.

%==============================================================================
\section{The Hierarchical Gaussian Filter}
%==============================================================================

\subsection{Intuition: Learning About Volatility}

Consider a simple example: an agent predicting whether a coin will land heads. In a stable environment, the coin's bias is constant. In a volatile environment, the bias changes over time.

A sophisticated agent should not only estimate the current bias but also estimate \emph{how quickly the bias is changing}. This is \textbf{volatility learning}.

The HGF implements this via a hierarchy:
\begin{itemize}
    \item \textbf{Level 1}: Observations (what we see)
    \item \textbf{Level 2}: Hidden states (what we believe about the world)
    \item \textbf{Level 3}: Volatility (how quickly the world is changing)
\end{itemize}

Higher levels modulate the learning rate at lower levels.

\subsection{Model Structure (3-Level Binary HGF)}

Let $u_t \in \{0, 1\}$ be a binary observation at time $t$. The generative model is:

\paragraph{Level 1 (Observation):}
\begin{equation}
    p(u_t \mid x_2^{(t)}) = \text{Bernoulli}\left(\sigma(x_2^{(t)})\right)
\end{equation}
where $\sigma(\cdot)$ is the logistic sigmoid and $x_2^{(t)}$ is the hidden state in log-odds (logit) space.

\paragraph{Level 2 (Hidden State):}
\begin{equation}
    x_2^{(t)} \sim \mathcal{N}\left(x_2^{(t-1)}, \exp(\kappa_1 x_3^{(t)} + \omega_1)\right)
\end{equation}

The variance of the random walk depends on:
\begin{itemize}
    \item $\omega_1$: Tonic (baseline) log-volatility
    \item $x_3^{(t)}$: Current volatility estimate from Level 3
    \item $\kappa_1$: Coupling strength between levels
\end{itemize}

\paragraph{Level 3 (Volatility):}
\begin{equation}
    x_3^{(t)} \sim \mathcal{N}\left(x_3^{(t-1)}, \exp(\theta)\right)
\end{equation}

This is another random walk with fixed tonic volatility $\theta$.

\begin{notebox}
\textbf{Key Insight}: The coupling parameter $\kappa_1$ determines how strongly volatility beliefs affect learning rate. This is crucial for computational psychiatry applications.
\end{notebox}

\subsection{Belief Update Equations}

The HGF uses a variational approximation to compute belief updates. Let $\mu_i^{(t)}$ and $\sigma_i^{(t)}$ denote the mean and variance of beliefs at level $i$.

\paragraph{Level 2 Update:}

The prior variance (before observing $u_t$) is:
\begin{equation}
    \hat{\sigma}_2^{(t)} = \sigma_2^{(t-1)} + \exp\left(\kappa_1 \mu_3^{(t-1)} + \omega_1\right)
    \label{eq:prior_variance}
\end{equation}

The \textbf{sensory prediction error} is:
\begin{equation}
    \delta_1^{(t)} = u_t - \sigma\left(\mu_2^{(t-1)}\right)
\end{equation}

The mean update follows a precision-weighted prediction error rule:
\begin{equation}
    \mu_2^{(t)} = \mu_2^{(t-1)} + \hat{\sigma}_2^{(t)} \cdot \delta_1^{(t)}
    \label{eq:mu2_update}
\end{equation}

The posterior variance is:
\begin{equation}
    \sigma_2^{(t)} = \left(\hat{\pi}_2^{(t)} + \pi_1^{(t)}\right)^{-1}
\end{equation}
where $\hat{\pi}_2^{(t)} = 1/\hat{\sigma}_2^{(t)}$ is the prior precision and $\pi_1^{(t)}$ is the sensory precision.

\paragraph{Level 3 Update:}

The \textbf{volatility prediction error} is:
\begin{equation}
    \delta_2^{(t)} = \frac{\sigma_2^{(t)} + \left(\mu_2^{(t)} - \mu_2^{(t-1)}\right)^2}{\hat{\sigma}_2^{(t)}} - 1
\end{equation}

This measures whether the observed change was larger or smaller than expected given the current volatility estimate.

The volatility belief updates as:
\begin{equation}
    \mu_3^{(t)} = \mu_3^{(t-1)} + \frac{1}{2} \hat{\sigma}_3^{(t)} \cdot w_3^{(t)} \cdot \delta_2^{(t)}
\end{equation}
where $w_3^{(t)}$ involves derivatives of the variance function.

\subsection{Relation to Variational Free Energy}

The HGF update equations can be derived by minimizing the \textbf{variational free energy}:
\begin{equation}
    F = D_{\text{KL}}\left[q(x) \,\|\, p(x \mid u)\right] - \log p(u)
\end{equation}

Under mean-field and Laplace approximations, the gradient descent on $F$ yields the update rules above. This connects the HGF to the broader framework of \textbf{Active Inference} and the \textbf{Free Energy Principle}.

\subsection{Comparison: Kalman Filter vs.\ HGF}

\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
\textbf{Aspect} & \textbf{Kalman Filter} & \textbf{HGF} \\
\midrule
Hierarchy & Single level & Multiple levels \\
Observations & Continuous, linear & Binary or continuous, nonlinear \\
Volatility & Fixed ($Q$) & Learned (Level 3) \\
Noise covariance & Known, constant & State-dependent, learned \\
Derivation & Exact Bayesian inference & Variational approximation \\
Learning rate & Fixed Kalman gain & Adaptive via volatility \\
\bottomrule
\end{tabular}
\caption{Comparison of Kalman filter and Hierarchical Gaussian Filter.}
\label{tab:kf_hgf}
\end{table}

In the limit of:
\begin{itemize}
    \item Linear observation model
    \item Single level
    \item Fixed volatility ($\kappa_1 = 0$)
\end{itemize}
the HGF reduces to a Kalman-like recursion.

%==============================================================================
\section{Computational Psychiatry Applications}
%==============================================================================

\subsection{The Bayesian Brain Hypothesis}

The \textbf{Bayesian brain hypothesis} proposes that the brain implements approximate Bayesian inference. Perception, learning, and action are understood as inference problems where:
\begin{itemize}
    \item Prior beliefs are combined with sensory evidence
    \item Precision weights determine the balance
    \item Prediction errors drive updates
\end{itemize}

Psychiatric disorders may reflect \emph{aberrant precision weighting} or \emph{pathological inference}.

\subsection{Parameter-Phenotype Mapping}

Different HGF parameters correspond to different computational phenotypes:

\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
\textbf{Parameter} & \textbf{Computational Effect} & \textbf{Clinical Phenotype} \\
\midrule
Low $\omega_1$ & Rigid priors, slow learning & Cognitive inflexibility, negative symptoms \\
High $\omega_1$ & Unstable beliefs & Aberrant salience, positive symptoms \\
High $\kappa_1$ & Hypersensitive to volatility & Affective instability (BPD) \\
Low $\kappa_1$ & Ignores volatility cues & Contextual insensitivity (ASD) \\
High $\theta$ (response) & Deterministic choices & Compulsive behavior \\
Low $\theta$ & Random choices & Disorganization, amotivation \\
\bottomrule
\end{tabular}
\caption{Mapping HGF parameters to clinical phenotypes.}
\label{tab:phenotypes}
\end{table}

\subsection{Example: Borderline Personality Disorder}

Consider a model of Borderline Personality Disorder (BPD) based on elevated $\kappa_1$:

From Equation~\eqref{eq:prior_variance}, the prior variance is:
\begin{equation}
    \hat{\sigma}_2 = \sigma_2 + \exp(\kappa_1 \mu_3 + \omega_1)
\end{equation}

When $\kappa_1$ is pathologically high (e.g., $\kappa_1 = 3$ vs.\ healthy $\kappa_1 = 1$), small fluctuations in volatility belief $\mu_3$ cause \emph{exponentially larger} changes in prior variance.

\textbf{Consequences}:
\begin{enumerate}
    \item Minor environmental changes trigger massive belief revision
    \item Emotional states swing rapidly
    \item Relationships feel unpredictable
    \item Identity appears unstable
\end{enumerate}

This provides a \emph{computational mechanism} for the core features of BPD.

\subsection{Neural Correlates}

The HGF's computational variables have empirical neural correlates:

\begin{itemize}
    \item \textbf{$\delta_1$ (sensory PE)}: Correlates with Feedback-Related Negativity (FRN) in EEG, striatal activation in fMRI
    \item \textbf{$\delta_2$ (volatility PE)}: Correlates with Anterior Cingulate Cortex (ACC) activation
    \item \textbf{$\hat{\pi}_2$ (prior precision)}: May relate to frontal theta oscillations
    \item \textbf{$\pi_1$ (sensory precision)}: May relate to posterior alpha suppression
\end{itemize}

These mappings enable neuroimaging validation of computational models.

%==============================================================================
\section{Application to Ara and NeuroBalance}
%==============================================================================

\subsection{Ara: The HGF as Cognitive Architecture}

Ara uses the HGF as part of its cognitive layer (TGSFN):
\begin{itemize}
    \item \textbf{L1: Homeostatic Core} $\leftrightarrow$ Level 1-2 HGF (needs, drives)
    \item \textbf{L2: Appraisal Engine} $\leftrightarrow$ Level 2-3 HGF (cognitive appraisal)
    \item \textbf{L3: Gating Controller} $\leftrightarrow$ Precision-weighted control signals
    \item \textbf{L4: Memory \& Identity} $\leftrightarrow$ Meta-learning, priors
\end{itemize}

The \texttt{ara.hgf} package provides:
\begin{itemize}
    \item Core update equations (\texttt{hgf\_update\_3level})
    \item Task environments (volatility switching, reversal learning)
    \item Parameter fitting and recovery validation
    \item Pathological presets (BPD, schizophrenia, etc.)
    \item Real-time HUD visualization
\end{itemize}

\subsection{NeuroBalance: Precision as Intervention Target}

The NeuroBalance concept proposes:
\begin{enumerate}
    \item \textbf{Measure}: Real-time EEG biomarkers for $\hat{\pi}_2$ (frontal theta) and $\pi_1$ (posterior alpha)
    \item \textbf{Compute}: Precision ratio or imbalance metric
    \item \textbf{Modulate}: Apply targeted tACS to shift precision weighting toward healthy range
\end{enumerate}

\begin{notebox}
\textbf{Status}: The HGF formalism and parameter-phenotype mapping are established in the literature. The closed-loop precision modulation is a \emph{research hypothesis} requiring empirical validation.
\end{notebox}

\subsection{Validation Ladder}

We distinguish between what is established and what requires validation:

\begin{enumerate}
    \item \textbf{Established}: HGF as computational model, parameter fitting to behavior
    \item \textbf{Established}: Correlation between fitted parameters and clinical measures
    \item \textbf{Established}: EEG/fMRI correlates of prediction errors
    \item \textbf{Frontier}: Precision biomarkers (theta/alpha) for real-time estimation
    \item \textbf{Frontier}: Causal modulation of precision via tACS
    \item \textbf{Frontier}: Clinical outcomes from closed-loop intervention
\end{enumerate}

The \texttt{ara.hgf} package provides simulation infrastructure for levels 1-4, enabling hypothesis development and pipeline validation before empirical testing.

%==============================================================================
\section{Variational Autoencoders for Phenotype Representation}
%==============================================================================

\subsection{Motivation: Learning Latent Structure}

Beyond fitting HGF parameters to individual trajectories, we seek a \emph{generative model} of computational phenotypes---a low-dimensional representation that:
\begin{enumerate}
    \item Captures the essential structure of HGF trajectories
    \item Enables phenotype classification and clustering
    \item Supports generation of new synthetic trajectories
    \item Provides interpretable dimensions corresponding to model parameters
\end{enumerate}

Variational Autoencoders (VAEs) provide a principled approach to learning such representations via amortized variational inference.

\subsection{VAE Architecture for HGF Trajectories}

A VAE consists of two components:
\begin{itemize}
    \item \textbf{Encoder} $q_\phi(z \mid x)$: Maps trajectories to latent distributions
    \item \textbf{Decoder} $p_\theta(x \mid z)$: Reconstructs trajectories from latent codes
\end{itemize}

For HGF trajectories, we encode the sequence:
\begin{equation}
    x = \left[\mu_2^{(1)}, \sigma_2^{(1)}, \delta_1^{(1)}, \ldots, \mu_2^{(T)}, \sigma_2^{(T)}, \delta_1^{(T)}\right]
\end{equation}

The encoder outputs parameters of a Gaussian:
\begin{equation}
    q_\phi(z \mid x) = \mathcal{N}\left(\mu_\phi(x), \text{diag}(\sigma^2_\phi(x))\right)
\end{equation}

Training maximizes the Evidence Lower Bound (ELBO):
\begin{equation}
    \mathcal{L}(\theta, \phi; x) = \mathbb{E}_{z \sim q_\phi}[\log p_\theta(x \mid z)] - \beta \cdot D_{\text{KL}}(q_\phi(z \mid x) \,\|\, p(z))
\end{equation}
where $p(z) = \mathcal{N}(0, I)$ is the prior and $\beta \geq 1$ encourages disentanglement.

\subsection{Disentanglement: The Goal}

A \textbf{disentangled} representation has three properties:
\begin{enumerate}
    \item \textbf{Modularity}: Each latent dimension encodes at most one generative factor
    \item \textbf{Compactness}: Each generative factor is encoded by few dimensions
    \item \textbf{Explicitness}: Factors can be read out by simple predictors
\end{enumerate}

For HGF trajectories, the ideal is:
\begin{align}
    z_1 &\approx \omega_2 \quad \text{(tonic volatility)} \\
    z_2 &\approx \kappa_1 \quad \text{(coupling strength)} \\
    z_3 &\approx \theta \quad \text{(response temperature)}
\end{align}

If achieved, the latent space naturally separates phenotypes.

\subsection{Disentanglement Metrics}

We evaluate latent structure using three families of metrics:

\paragraph{Predictor-Based (DCI):}
Train classifiers to predict factors from latents. The \textbf{DCI score} decomposes into:
\begin{itemize}
    \item \textbf{Disentanglement}: $1 - H(R_{\cdot,j}) / \log K$ for each latent dimension
    \item \textbf{Completeness}: $1 - H(R_{i,\cdot}) / \log D$ for each factor
    \item \textbf{Informativeness}: Average prediction accuracy
\end{itemize}
where $R_{ij}$ is the importance of latent $j$ for factor $i$.

\paragraph{Information-Based (MIG):}
The \textbf{Mutual Information Gap} measures, for each factor, the difference between the two latent dimensions with highest mutual information:
\begin{equation}
    \text{MIG} = \frac{1}{K} \sum_{k=1}^{K} \frac{1}{H(v_k)} \left( I(z_{j^*}; v_k) - \max_{j \neq j^*} I(z_j; v_k) \right)
\end{equation}
where $j^* = \arg\max_j I(z_j; v_k)$.

\paragraph{Exclusivity-Based (EDI):}
The \textbf{Exclusivity Disentanglement Index} addresses limitations of MIG by measuring how exclusively each latent dimension captures information about factors:
\begin{equation}
    \text{EDI}_{\text{mod}} = \max_i \frac{I(z_j; v_i)}{\sum_k I(z_j; v_k)} - \frac{1}{K-1} \sum_{k \neq i^*} \frac{I(z_j; v_k)}{\sum_k I(z_j; v_k)}
\end{equation}

\subsection{Evaluation Protocol}

\paragraph{Synthetic Benchmarks:}
For simulated trajectories where ground-truth HGF parameters are known:
\begin{quote}
We compute predictor-based (DCI, SAP) and information-based (MIG, EDI) metrics to quantify modularity, compactness, and explicitness. Architectures and hyperparameters are selected based on these scores.
\end{quote}

\paragraph{Real Behavioral Data:}
For empirical data where true generative factors are unknown:
\begin{quote}
We use a DCI-style predictor analysis on available labels (task condition, clinical group, fitted HGF parameters) and evaluate utility via downstream tasks (phenotype classification, parameter recovery accuracy), rather than claiming absolute disentanglement.
\end{quote}

\begin{notebox}
\textbf{Key Constraint}: Almost all disentanglement metrics assume known ground-truth factors. For real data, we can only validate approximate structure using proxy labels and downstream task performance.
\end{notebox}

\subsection{Implementation}

The \texttt{ara.vae} package provides:
\begin{itemize}
    \item \texttt{TrajectoryVAE}: LSTM-based encoder/decoder for HGF sequences
    \item \texttt{compute\_dci}, \texttt{compute\_mig}, \texttt{compute\_sap}, \texttt{compute\_edi}: Standard metrics
    \item \texttt{generate\_phenotype\_dataset}: Trajectory generation from pathological presets
    \item \texttt{evaluate\_disentanglement}: Comprehensive report with all metrics
\end{itemize}

%==============================================================================
\section{Summary}
%==============================================================================

The Hierarchical Gaussian Filter provides:
\begin{enumerate}
    \item A principled extension of Kalman filtering to hierarchical, volatility-learning settings
    \item Precision-weighted prediction error updates grounded in variational inference
    \item A computational framework for modeling psychiatric disorders as inference abnormalities
    \item Testable predictions for neural correlates of Bayesian inference
\end{enumerate}

Combined with Variational Autoencoders for latent representation:
\begin{enumerate}
    \item Disentangled latent spaces can separate computational phenotypes
    \item Standard metrics (DCI, MIG, EDI) quantify representation quality
    \item Generative models enable synthetic data creation and parameter recovery
\end{enumerate}

For Ara and NeuroBalance, these tools serve as:
\begin{itemize}
    \item The mathematical backbone for belief dynamics
    \item A bridge between behavior, parameters, and neural signals
    \item A testbed for computational psychiatry hypotheses
    \item A generative framework for phenotype modeling and clustering
\end{itemize}

%==============================================================================
% References
%==============================================================================
\bibliographystyle{plainnat}

\begin{thebibliography}{9}

\bibitem{mathys2011}
Mathys, C., Daunizeau, J., Friston, K.~J., \& Stephan, K.~E. (2011).
\newblock A Bayesian foundation for individual learning under uncertainty.
\newblock \emph{Frontiers in Human Neuroscience}, 5, 39.

\bibitem{mathys2014}
Mathys, C.~D., Lomakina, E.~I., Daunizeau, J., Iglesias, S., Brodersen, K.~H., Friston, K.~J., \& Stephan, K.~E. (2014).
\newblock Uncertainty in perception and the Hierarchical Gaussian Filter.
\newblock \emph{Frontiers in Human Neuroscience}, 8, 825.

\bibitem{adams2013}
Adams, R.~A., Stephan, K.~E., Brown, H.~R., Frith, C.~D., \& Friston, K.~J. (2013).
\newblock The computational anatomy of psychosis.
\newblock \emph{Frontiers in Psychiatry}, 4, 47.

\bibitem{lawson2017}
Lawson, R.~P., Mathys, C., \& Rees, G. (2017).
\newblock Adults with autism overestimate the volatility of the sensory environment.
\newblock \emph{Nature Neuroscience}, 20(9), 1293--1299.

\bibitem{friston2010}
Friston, K. (2010).
\newblock The free-energy principle: a unified brain theory?
\newblock \emph{Nature Reviews Neuroscience}, 11(2), 127--138.

\bibitem{kingma2014}
Kingma, D.~P., \& Welling, M. (2014).
\newblock Auto-encoding variational {B}ayes.
\newblock In \emph{Proceedings of ICLR}.

\bibitem{higgins2017}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., Mohamed, S., \& Lerchner, A. (2017).
\newblock $\beta$-{VAE}: Learning basic visual concepts with a constrained variational framework.
\newblock In \emph{Proceedings of ICLR}.

\bibitem{eastwood2018}
Eastwood, C., \& Williams, C.~K.~I. (2018).
\newblock A framework for the quantitative evaluation of disentangled representations.
\newblock In \emph{Proceedings of ICLR}.

\end{thebibliography}

\end{document}
